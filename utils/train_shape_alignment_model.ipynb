{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a shape alignment model\n",
    "Use the `shape_align` environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from structural.loss import chamfer_distance as cmf\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "import pandas as pd\n",
    "from unidip import UniDip\n",
    "import unidip.dip as dip\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import RDLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX add path to point_cloud_methods repository\n",
    "shape_align_path = '/path/to/point_cloud_methods/repository'\n",
    "sys.path.append(shape_align_path)\n",
    "\n",
    "from structural import models, molecule\n",
    "from structural.models import PCRSingleMasked, PCRSepFeat\n",
    "from structural.molecule import Molecules, MoleculeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('data')\n",
    "output_folder = Path.joinpath(data_folder, 'shape_align')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protacdb = pd.read_csv(Path.joinpath(data_folder, 'protacdb_extended_linkers.csv'))\n",
    "df_protacdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdb = pd.read_csv(Path.joinpath(data_folder, 'pdb_systems_data.csv'))\n",
    "df_pdb.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure case studies are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigated_sys = ['5T35', '7ZNT', '6HAY', '6HAX', '7S4E', '6BN7', '6BOY', '7JTP', '7Q2J', '7JTO']\n",
    "df_pdb = df_pdb[df_pdb['PDB'].isin(investigated_sys)]\n",
    "# check if extended linkers in protacdb are in pdb\n",
    "df_missing = df_pdb[~df_pdb['linker_ext_smiles'].isin(df_protacdb['ext_linker_smiles'])]\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df_protacdb['ext_linker_smiles'].tolist()\n",
    "smiles.extend(df_missing['linker_ext_smiles'].tolist())\n",
    "# drop duplicates\n",
    "smiles = list(set(smiles))\n",
    "query_smiles = df_pdb.linker_ext_smiles.tolist()\n",
    "query_indices = [smiles.index(query_smile) for query_smile in query_smiles]\n",
    "len(smiles), len(query_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [Chem.MolFromSmiles(smi) for smi in query_smiles]\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(300,200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_batches = []\n",
    "for query_id in tqdm(query_indices, total=len(query_indices), desc='Self align queries'): # make data to learn self alignment\n",
    "    for _ in tqdm(range(10), desc='Self align subsets'):\n",
    "        rest = [query_id]*5\n",
    "        stored = None\n",
    "        count = 0\n",
    "        batch_num = 16\n",
    "        while stored is None:\n",
    "            try:\n",
    "                training_batches += MoleculeInfo.from_smiles(smiles[query_id]).get_training_batches([smiles[i] for i in rest], batch_num=2, batch_size=int(batch_num))\n",
    "                stored = 1\n",
    "            except ValueError:\n",
    "                stored = 1\n",
    "                continue\n",
    "            except RuntimeError: # retrying can fix as dependent on conformer generation (stochastic)\n",
    "                count += 1\n",
    "                if count > 10:\n",
    "                    batch_num = batch_num / 2\n",
    "                    print(f'Self of index {query_id}: Reducing batch size to {batch_num}')\n",
    "                    count = 0\n",
    "                    if batch_num < 1:\n",
    "                        print(f'Self of index {query_id}: Batch size too small, skipping')\n",
    "                        stored = 1\n",
    "                continue\n",
    "        \n",
    "for query_id in tqdm(query_indices, total=len(query_indices), desc='Others align queries'): # make data for query vs others alignments\n",
    "    for _ in tqdm(range(10), desc='Others align subsets'):\n",
    "        rest = np.random.choice(range(len(smiles)), 5)\n",
    "        stored = None\n",
    "        count = 0\n",
    "        batch_num = 16\n",
    "        while stored is None:\n",
    "            try:\n",
    "                training_batches += MoleculeInfo.from_smiles(smiles[query_id]).get_training_batches([smiles[i] for i in rest], batch_num=2, batch_size=int(batch_num))\n",
    "                stored = 1\n",
    "            except ValueError:\n",
    "                stored = 1\n",
    "                continue\n",
    "            except RuntimeError: # retrying can fix as dependent on conformer generation (stochastic)\n",
    "                count += 1\n",
    "                if count > 20:\n",
    "                    batch_num = batch_num / 2\n",
    "                    print(f'Others of index {query_id}: Reducing batch size to {batch_num}')\n",
    "                    count = 0\n",
    "                    if batch_num < 1:\n",
    "                        print(f'Others of index {query_id}: Batch size too small, skipping')\n",
    "                        stored = 1\n",
    "                continue\n",
    "\n",
    "validation_batches = []\n",
    "\n",
    "for query_id in tqdm(query_indices, total=len(query_indices), desc='Validation queries'): # make some validation batches (self vs others)\n",
    "    for _ in tqdm(range(10), desc='Validation subsets'):\n",
    "        rest = np.random.choice(range(len(smiles)), 1)\n",
    "        stored = None\n",
    "        count = 0\n",
    "        batch_num = 16\n",
    "        while stored is None:\n",
    "            try:\n",
    "                validation_batches += MoleculeInfo.from_smiles(smiles[query_id]).get_training_batches([smiles[i] for i in rest], batch_num=1, batch_size=int(batch_num))\n",
    "                stored = 1\n",
    "            except ValueError:\n",
    "                stored = 1\n",
    "                continue\n",
    "            except RuntimeError: # retrying can fix as dependent on conformer generation (stochastic)\n",
    "                count += 1\n",
    "                if count > 10:\n",
    "                    batch_num = batch_num / 2\n",
    "                    print(f'Val of index {query_id}: Reducing batch size to {batch_num}')\n",
    "                    count = 0\n",
    "                    if batch_num < 1:\n",
    "                        print(f'Val of index {query_id}: Batch size too small, skipping')\n",
    "                        stored = 1\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_filepath = Path.joinpath(output_folder, 'shape_align_batches.pth')\n",
    "torch.save((training_batches, validation_batches), batch_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_batches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = models.DataLoader(training_batches)\n",
    "vd = models.DataLoader(validation_batches)\n",
    "\n",
    "trainer = Trainer(accelerator='gpu', max_epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCRSingleMasked(3, coarse_attention_dim=16, coarse_nheads=8, validation_data=validation_batches)\n",
    "print(\"Average RANSAC distance:\", model.validation_ransac_distance) # shows RANSAC alignment scores for validation\n",
    "trainer.fit(model, td, vd) # \"improvement over ransac\" for validation should be above 1 as an indicator that it's performing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = Path.joinpath(output_folder, 'protacdb_extlinker_model_align.pth')\n",
    "torch.save(model, model_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = Path.joinpath(output_folder, 'protacdb_extlinker_model_align.pth')\n",
    "model = torch.load(model_filepath)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [Chem.MolFromSmiles(smi) for smi in query_smiles]\n",
    "Chem.Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get PDB ID per query_smiles from df_pdb\n",
    "pdb_folderpaths = Path.joinpath(data_folder, 'protac_dataset', 'dataset')\n",
    "\n",
    "query_pdb_ids = {}\n",
    "for query_smile in query_smiles:\n",
    "    PDB_id = df_pdb[df_pdb['linker_ext_smiles'] == query_smile]['PDB'].values[0]\n",
    "    sdf_filepath = pdb_folderpaths / PDB_id / f'{PDB_id}_fragments' / f'{PDB_id}_linker_extended.sdf'\n",
    "    query_pdb_ids[query_smile] = (PDB_id, sdf_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(mol, atom_idxs):\n",
    "    '''\n",
    "    Returns the coordinates of the atom indices.\n",
    "    '''\n",
    "    coords = []\n",
    "    for idx in atom_idxs:\n",
    "        coords.append(mol.GetConformer().GetAtomPosition(idx))\n",
    "    return coords\n",
    "\n",
    "def calc_rmsd(coords1, coords2):\n",
    "    '''\n",
    "    Calculates the RMSD between two sets of coordinates. \n",
    "    Need to be in matching order.\n",
    "    '''\n",
    "    rmsd = 0\n",
    "    for i in range(len(coords1)):\n",
    "        rmsd += (coords1[i].x - coords2[i].x)**2 + (coords1[i].y - coords2[i].y)**2 + (coords1[i].z - coords2[i].z)**2\n",
    "    rmsd = np.sqrt(rmsd/len(coords1))\n",
    "    \n",
    "    return rmsd\n",
    "\n",
    "def get_rmsd(pose1_path, pose2_path):\n",
    "    pose1 = Chem.MolFromMolFile(pose1_path)\n",
    "    pose2 = Chem.MolFromMolFile(pose2_path)\n",
    "    pose1_indices = pose1.GetSubstructMatch(pose2)\n",
    "    pose2_indices = [a.GetIdx() for a in pose2.GetAtoms()]\n",
    "    pose1_coords = get_coords(pose1, pose1_indices)\n",
    "    pose2_coords = get_coords(pose2, pose2_indices)\n",
    "    rmsd = calc_rmsd(pose1_coords, pose2_coords)\n",
    "    return rmsd\n",
    "\n",
    "def align_and_save(indices, scores, rmsds, pose_folder, query_pose, model, PDB_id, sdf_filepath):\n",
    "    for i in tqdm(indices, desc='Self align repeats'):\n",
    "        alignment = query_pose.align_to_multiconformer_smiles_fast2(query_smile, model, number_of_conformers=16, es_weight=0)\n",
    "        scores[i] = alignment.chamfer_distance\n",
    "        pose = alignment.molecule_2\n",
    "        pose_path = Path.joinpath(pose_folder, f'{PDB_id}_{i}_pose.mol')\n",
    "        pose.write_to_file(pose_path.as_posix())\n",
    "        rmsds[i] = get_rmsd(sdf_filepath.as_posix(), pose_path.as_posix())\n",
    "    return scores, rmsds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align query to themselves n times each\n",
    "n = 32\n",
    "pose_folder = Path.joinpath(output_folder, 'poses_model_validation')\n",
    "pose_folder.mkdir(parents=False, exist_ok=True)\n",
    "query_self_alignments = {}\n",
    "for query_smile in tqdm(query_smiles, total=len(query_smiles), desc='Self align queries'):\n",
    "    PDB_id, sdf_filepath = query_pdb_ids[query_smile]\n",
    "    query_pose = MoleculeInfo.from_sdf(sdf_filepath.as_posix())\n",
    "    rpt_indices = [i for i in range(n)]\n",
    "    scores = [np.nan]*n\n",
    "    rmsds = [np.nan]*n\n",
    "    scores, rmsds = align_and_save(rpt_indices, scores, rmsds, pose_folder, query_pose, model, PDB_id, sdf_filepath)\n",
    "    rmsds_sorted = np.msort(rmsds)\n",
    "    intervals = UniDip(rmsds_sorted).run()\n",
    "    try:\n",
    "        split_point = (rmsds_sorted[intervals[0][1]] + rmsds_sorted[intervals[1][0]]) / 2\n",
    "    except:\n",
    "        split_point = (rmsds_sorted[intervals[0][0]] + rmsds_sorted[intervals[0][1]]) / 2\n",
    "    indices_fail = [i for i in range(n) if rmsds[i] > split_point]\n",
    "    while indices_fail:\n",
    "        scores, rmsds = align_and_save(indices_fail, scores, rmsds, pose_folder, query_pose, model, PDB_id, sdf_filepath)\n",
    "        indices_fail = [i for i in range(n) if rmsds[i] > split_point]\n",
    "    query_self_alignments[PDB_id] = (scores, rmsds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_self_pose_align = {}\n",
    "for query_smile in tqdm(query_smiles, total=len(query_smiles), desc='Self align query poses'):\n",
    "    PDB_id, sdf_filepath = query_pdb_ids[query_smile]\n",
    "    query_pose = MoleculeInfo.from_sdf(sdf_filepath.as_posix())\n",
    "    own_dist = query_pose.get_chamfer_distance(query_pose)\n",
    "    query_self_pose_align[PDB_id] = own_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through dict\n",
    "df_scored = pd.DataFrame(columns=['PDB', 'pose_id', 'chamfer_distance'])\n",
    "for query_id, results in query_self_alignments.items():\n",
    "    scores, rmsds = results\n",
    "    query_id_repeat = [query_id] * len(scores)\n",
    "    sub_ids = [i for i in range(len(scores))]\n",
    "    # add to df\n",
    "    df_sub = pd.DataFrame({'PDB': query_id_repeat, 'pose_id': sub_ids, 'chamfer_distance': scores, 'RMSD': rmsds})\n",
    "    df_scored = pd.concat([df_scored, df_sub], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add own distance to df\n",
    "own_distances = []\n",
    "for query_id in df_scored['PDB']:\n",
    "    own_distances.append(query_self_pose_align[query_id])\n",
    "df_scored['own_distance'] = own_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scored.to_csv(Path.joinpath(output_folder, 'align_model_val_self_alignments.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stats for all systems: mean, min, max\n",
    "df_scored.groupby('PDB').chamfer_distance.agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = list(query_self_alignments.values())\n",
    "all_chamfer_distances = [scores for scores, rmsds in all_scores]\n",
    "all_rmsds = [rmsds for scores, rmsds in all_scores]\n",
    "all_PDB_ids = list(query_self_alignments.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a color dictionary with PDB id as key and color as value\n",
    "color_dict = {}\n",
    "for i, PDB_id in enumerate(all_PDB_ids):\n",
    "    # extract colors from the color map\n",
    "    color = cm.jet(i/len(all_PDB_ids))\n",
    "    color_dict[PDB_id] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6));\n",
    "for i, PDB_id in enumerate(all_PDB_ids):\n",
    "    chamfer_sub = all_chamfer_distances[i]\n",
    "    violin_parts = ax.violinplot(chamfer_sub, showmeans=True, showmedians=True, \n",
    "        widths=0.7, positions=[i], showextrema=False);\n",
    "    violin_parts['cmedians'].set_color('black');\n",
    "    violin_parts['cmedians'].set_linewidth(2);\n",
    "    violin_parts['cmedians'].set_linestyle((0, (1,1)));\n",
    "    violin_parts['cmeans'].set_color('black');\n",
    "    violin_parts['cmedians'].set_linewidth(2)\n",
    "    for pc in violin_parts['bodies']:\n",
    "        pc.set_facecolor(color_dict[PDB_id])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.8)\n",
    "violin_parts['cmedians'].set_label('median of random conformers');\n",
    "violin_parts['cmeans'].set_label('mean of random conformers');\n",
    "ax.set_xticks(range(10));\n",
    "ax.set_xticklabels(all_PDB_ids, rotation=45);\n",
    "ax.set_xlabel('corresponding PDB', fontsize=14);\n",
    "ax.set_ylabel('chamfer distance', fontsize=14);\n",
    "# add own distance\n",
    "own_distances = [query_self_pose_align[PDB_id] for PDB_id in all_PDB_ids]\n",
    "ax.scatter(range(len(all_chamfer_distances)), own_distances, color='darkred', label='conformer equal to query', s=5);\n",
    "ax.legend();\n",
    "plt.savefig(Path.joinpath(output_folder, 'shape_ailgn_val_self_align_violin.pdf'), bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlation between chamfer distance and RMSD\n",
    "fig, ax = plt.subplots(figsize=(10, 6));\n",
    "for PDB_id in all_PDB_ids:\n",
    "    df_scored_sub = df_scored[df_scored['PDB'] == PDB_id]\n",
    "    ax.scatter(df_scored_sub['chamfer_distance'], df_scored_sub['RMSD'], label=PDB_id, color=color_dict[PDB_id], s=20);\n",
    "    ax.set_xlabel('chamfer distance');\n",
    "    ax.set_ylabel('RMSD');\n",
    "    ax.legend();\n",
    "ax.set_xlabel('chamfer distance', fontsize=14);\n",
    "ax.set_ylabel('RMSD', fontsize=14);\n",
    "plt.legend(loc='lower right');\n",
    "plt.savefig(Path.joinpath(output_folder, 'shape_ailgn_val_self_align2rmsd_scatter.pdf'), bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rotational bonds per PDB\n",
    "def get_nROT(df, PDB):\n",
    "    smiles = df[df['PDB'] == PDB]['linker_ext_smiles'].values[0]\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    nROT = Chem.rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
    "    return nROT\n",
    "df_scored['nROT'] = df_scored['PDB'].apply(lambda x: get_nROT(df_pdb, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot nROT vs. mean chamfer distance\n",
    "fig, ax = plt.subplots(figsize=(6, 5));\n",
    "for PDB_id in all_PDB_ids:\n",
    "    df_scored_sub = df_scored[df_scored['PDB'] == PDB_id]\n",
    "    mean_chamfer = df_scored_sub['chamfer_distance'].mean()\n",
    "    nROT = df_scored_sub['nROT'].values[0]\n",
    "    ax.scatter(nROT, mean_chamfer, label=PDB_id, color=color_dict[PDB_id], s=30);\n",
    "    ax.set_xlabel('nROT', fontsize=14);\n",
    "    ax.set_ylabel('average chamfer distance', fontsize=14);\n",
    "    ax.legend();\n",
    "plt.savefig(Path.joinpath(output_folder, 'shape_ailgn_val_self_align_nROT_vs_mean_chamfer.pdf'), bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "322e2706a3b065ade57181190dee4d3fc174f87cda022382b010766df70aa18b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
